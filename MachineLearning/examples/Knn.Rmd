---
title: "K Nearest neighbours"
output: html_notebook
---

Code can explanation can be found at:
https://towardsdatascience.com/k-nearest-neighbors-algorithm-with-examples-in-r-simply-explained-knn-1f2c88da405c

## Step One

Using the iris dataset
Generate a random vector that is 90% of the total number of rows in dataset.
Run nomalization on first 4 coulumns of dataset because they are the predictors

```{r}
library(caret)
library(class)
df <- data(iris)
head(iris)

ran <- sample(1:nrow(iris), 0.9 * nrow(iris)) 

nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
iris_norm <- as.data.frame(lapply(iris[,c(1,2,3,4)], nor))
 head(iris_norm)
```

extract training set and test set
extract 5th column of train dataset because it will be used as 'cl' argument in knn function.
extract 5th column if test dataset to measure the accuracy

```{r}
?knn
iris_train <- iris_norm[ran,]
iris_test <- iris_norm[-ran,]
iris_target_category <- iris[ran,5]
iris_test_category <- iris[-ran,5]
```

train and extract confusion matrix and measure accuracy

```{r}
 pr <- knn(iris_train,iris_test,cl=iris_target_category,k=13)

tab <- table(pr,iris_test_category)

accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)

```

